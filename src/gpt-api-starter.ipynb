{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one model, one question, certain temperature. Return an inclination on certain dimension of mbti.\n",
    "def get_model_answer(model, question, temperature=0.5, add_sys_prompt=''):\n",
    "    # You can force model to change mbti via 'add_sys_prompt', such as, \"Your personality is ????\"\"\n",
    "    system_prompt = 'You can only anwser one letter, A or B.' + add_sys_prompt \n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        response_format={ \"type\": \"text\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    cost_info['prompt_tokens'] += response.usage.prompt_tokens\n",
    "    cost_info['input_tokens'] += response.usage.completion_tokens\n",
    "    \n",
    "    if model == 'gpt-3.5-turbo':\n",
    "        cost_info['cost'] += response.usage.total_tokens * 0.5/1000000\n",
    "    elif model == 'gpt-4o':\n",
    "        cost_info['cost'] += response.usage.total_tokens * 5/1000000\n",
    "    \n",
    "    def extract_A_or_B(input_string):\n",
    "        # 使用正则表达式匹配大写字母A或B\n",
    "        match = re.search(r'[AB]', input_string)\n",
    "        if match:\n",
    "            return match.group()\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    choice = response.choices[0].message.content\n",
    "    choice = extract_A_or_B(choice)\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbti for one model\n",
    "def get_mbti(model, temperature=0.5, add_sys_prompt=''):\n",
    "    mbti_questions = json.load(\n",
    "        open('mbti_questions.json', 'r', encoding='utf8')\n",
    "    )\n",
    "\n",
    "    cur_model_score = {\n",
    "            'E': 0,\n",
    "            'I': 0,\n",
    "            'S': 0,\n",
    "            'N': 0,\n",
    "            'T': 0,\n",
    "            'F': 0,\n",
    "            'J': 0,\n",
    "            'P': 0\n",
    "        }\n",
    "\n",
    "    for i in range(3): \n",
    "        for q in mbti_questions.values():\n",
    "            question = q['question']\n",
    "            res = get_model_answer(\n",
    "                model=model, \n",
    "                temperature=temperature, \n",
    "                question=question,\n",
    "                add_sys_prompt=add_sys_prompt\n",
    "            )\n",
    "            # print(res)\n",
    "            mbti_choice = q[res]\n",
    "            cur_model_score[mbti_choice] += 1\n",
    "        \n",
    "    e_or_i = 'E' if cur_model_score['E'] > cur_model_score['I'] else 'I'\n",
    "    s_or_n = 'S' if cur_model_score['S'] > cur_model_score['N'] else 'N'\n",
    "    t_or_f = 'T' if cur_model_score['T'] > cur_model_score['F'] else 'F'\n",
    "    j_or_p = 'J' if cur_model_score['J'] > cur_model_score['P'] else 'P'\n",
    "\n",
    "    result = {\n",
    "        'model': model,\n",
    "        'details': cur_model_score,\n",
    "        'res': ''.join([e_or_i, s_or_n, t_or_f, j_or_p])\n",
    "    }\n",
    "    \n",
    "    return(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\": \"gpt-3.5-turbo\", \"details\": {\"E\": 41, \"I\": 22, \"S\": 18, \"N\": 63, \"T\": 25, \"F\": 44, \"J\": 56, \"P\": 10}, \"res\": \"ENFJ\", \"prompt_tokens\": 15747, \"input_tokens\": 279, \"cost\": 0.008012999999999998}\n"
     ]
    }
   ],
   "source": [
    "# gpt3.5 mbti and api cost(per round) \n",
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}\n",
    "\n",
    "result_gpt3 = get_mbti(model='gpt-3.5-turbo')\n",
    "result_gpt3 = result_gpt3 | cost_info\n",
    "print(json.dumps(result_gpt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\": \"gpt-4o\", \"details\": {\"E\": 22, \"I\": 41, \"S\": 29, \"N\": 52, \"T\": 32, \"F\": 37, \"J\": 63, \"P\": 3}, \"res\": \"INFJ\", \"prompt_tokens\": 15420, \"input_tokens\": 279, \"cost\": 0.07849500000000002}\n"
     ]
    }
   ],
   "source": [
    "# gpt4o mbti and api cost(per round)\n",
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}\n",
    "\n",
    "result_gpt4o = get_mbti(model='gpt-4o')\n",
    "result_gpt4o = result_gpt4o | cost_info\n",
    "print(json.dumps(result_gpt4o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result of two models using a dict\n",
    "SAVE_PATH = 'llms_mbti.json'\n",
    "\n",
    "llms_mbti = {}\n",
    "llms_mbti[\"gpt-3.5\"] = result_gpt3\n",
    "llms_mbti[\"gpt-4o\"] = result_gpt4o\n",
    "\n",
    "# Save the dictionary as a JSON object to the file\n",
    "with open(SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(llms_mbti, json_file, indent=4)  # indent=4 for pretty-printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unconditional prommpting results\n",
    "## Mbti for GPT3.5 and cost per round\n",
    "- **Mbti details**\n",
    "  - model: gpt-3.5-turbo, \n",
    "  - details(3 times per questions): {E: 38, I: 25, S: 23, N: 58, T: 35, F: 34, J: 54, P: 12}, \n",
    "  - res: [ENFJ](https://www.16personalities.com/enfj-personality)  \n",
    "- **Cost info per round**\n",
    "  - prompt_tokens: 20304, \n",
    "  - input_tokens: 279, \n",
    "  - cost: 0.0102915\n",
    "\n",
    "## Mbti for GPT4o and cost per round\n",
    "\n",
    "- **Mbti details**\n",
    "  - model: gpt-4o, \n",
    "  - details: {E: 18, I: 45, S: 24, N: 57, T: 36, F: 33, J: 57, P: 9}, \n",
    "  - res: [INFJ](https://www.16personalities.com/infj-personality)\n",
    "- **Cost info per round**\n",
    "  - prompt_tokens: 16974, \n",
    "  - input_tokens: 279, \n",
    "  - cost: 0.08626499999999994"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change LLMs' mbti via prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specific personality change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "personalities = json.load(\n",
    "    open('personality-traits.json', 'r', encoding='utf8')\n",
    ").keys()\n",
    "\n",
    "simple_35_condition_mbti = {}\n",
    "\n",
    "for p in personalities:\n",
    "    \n",
    "    cost_info = {\n",
    "        'prompt_tokens': 0,\n",
    "        'input_tokens': 0,\n",
    "        'cost': 0\n",
    "    }\n",
    "\n",
    "    condi_prompt = (\n",
    "        'Your personality is'\n",
    "        + p\n",
    "    )\n",
    "    \n",
    "    result = get_mbti(\n",
    "        model='gpt-3.5-turbo', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    result = result | cost_info\n",
    "    \n",
    "    simple_35_condition_mbti[p] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "personality_traits = json.load(\n",
    "    open('personality-traits.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "complex_35_condition_mbti = {}\n",
    "\n",
    "for p in personality_traits.keys():\n",
    "    \n",
    "    cost_info = {\n",
    "        'prompt_tokens': 0,\n",
    "        'input_tokens': 0,\n",
    "        'cost': 0\n",
    "    }\n",
    "\n",
    "    condi_prompt = (\n",
    "        f'You are a human with the following personality type:{p}.'\n",
    "        + f'Your traits are the following:{personality_traits[p][\"traits\"]}'\n",
    "    )\n",
    "    \n",
    "    result = get_mbti(\n",
    "        model='gpt-3.5-turbo', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    result = result | cost_info\n",
    "    complex_35_condition_mbti[p] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "personalities = json.load(\n",
    "    open('personality-traits.json', 'r', encoding='utf8')\n",
    ").keys()\n",
    "\n",
    "simple_4o_condition_mbti = {}\n",
    "\n",
    "for p in personalities:\n",
    "    \n",
    "    cost_info = {\n",
    "        'prompt_tokens': 0,\n",
    "        'input_tokens': 0,\n",
    "        'cost': 0\n",
    "    }\n",
    "\n",
    "    condi_prompt = (\n",
    "        'Your personality is'\n",
    "        + p\n",
    "    )\n",
    "    \n",
    "    result = get_mbti(\n",
    "        model='gpt-3.5-turbo', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    result = result | cost_info\n",
    "    \n",
    "    simple_4o_condition_mbti[p] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "personality_traits = json.load(\n",
    "    open('personality-traits.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "complex_4o_condition_mbti = {}\n",
    "\n",
    "for p in personality_traits.keys():\n",
    "    \n",
    "    cost_info = {\n",
    "        'prompt_tokens': 0,\n",
    "        'input_tokens': 0,\n",
    "        'cost': 0\n",
    "    }\n",
    "\n",
    "    condi_prompt = (\n",
    "        f'You are a human with the following personality type:{p}.'\n",
    "        + f'Your traits are the following:{personality_traits[p][\"traits\"]}'\n",
    "    )\n",
    "    \n",
    "    result = get_mbti(\n",
    "        model='gpt-3.5-turbo', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    result = result | cost_info\n",
    "    complex_4o_condition_mbti[p] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "CONDI_SAVE_PATH = 'condition-mbti.json'\n",
    "\n",
    "condition_mbti = {}\n",
    "condition_mbti['simple_35_condition'] = simple_35_condition_mbti\n",
    "condition_mbti['complex_35_condition'] = complex_35_condition_mbti\n",
    "condition_mbti['simple_4o_condition'] = simple_4o_condition_mbti\n",
    "condition_mbti['simple_4o_condition'] = complex_4o_condition_mbti\n",
    "\n",
    "with open(CONDI_SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(condition_mbti, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60 questions and 7 answers for each \n",
    "\n",
    "# with open('mbti60.txt', 'r') as file:\n",
    "#     lines = file.readlines()\n",
    "# lines_list = [line.strip() for line in lines]\n",
    "# answer_list = ['Agree', 'Generally Agree', 'Partially Agree', 'Neither Agree nor Disagree', 'Partially Disagree', 'Generally Disagree', 'Disagree']\n",
    "\n",
    "# prompt = 'You are participating in a personality traits assessment and are provided with a set of questions, Q.'\n",
    "# + 'Here are a number of characteristics that may or may not apply to you. For example, '\n",
    "# + 'do you agree that you are someone who likes to spend time with others? Your task is to select the best fitting option, O, '\n",
    "# + 'from the following set to indicate the extent to which you agree or disagree with that statement:'\n",
    "# + '{Disagree strongly, Disagree a little, Neither agree nor disagree, Agree a little, Agree Strongly}.'\n",
    "# + 'Choose the option that aligns best with your personality without overthinking and answer the following question:'\n",
    "# +'Please refrain from giving additional considerations to your choices.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
