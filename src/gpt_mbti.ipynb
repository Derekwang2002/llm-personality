{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconditional prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\": \"gpt-3.5-turbo\", \"details\": {\"E\": 38, \"I\": 25, \"S\": 19, \"N\": 62, \"T\": 35, \"F\": 34, \"J\": 51, \"P\": 15}, \"res\": \"ENTJ\", \"prompt_tokens\": 12678, \"input_tokens\": 294, \"cost\": 0.006486000000000004}\n"
     ]
    }
   ],
   "source": [
    "# gpt3.5 mbti and api cost(per round) \n",
    "result_gpt3 = f.get_mbti(model='gpt-3.5-turbo')\n",
    "print(json.dumps(result_gpt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_tem_gpt3 = f.get_mbti(\n",
    "    model='gpt-3.5-turbo',\n",
    "    temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_tem_gpt3 = f.get_mbti(\n",
    "    model='gpt-3.5-turbo',\n",
    "    temperature=1.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconditional_mbti_gpt3 = {}\n",
    "unconditional_mbti_gpt3[\"0.5 temperature unconditional\"] = result_gpt3\n",
    "unconditional_mbti_gpt3[\"1 temperature unconditional\"] = middle_tem_gpt3\n",
    "unconditional_mbti_gpt3[\"1.7 temperature unconditional\"] = high_tem_gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\": \"gpt-4o\", \"details\": {\"E\": 22, \"I\": 41, \"S\": 21, \"N\": 60, \"T\": 35, \"F\": 34, \"J\": 60, \"P\": 6}, \"res\": \"INTJ\", \"prompt_tokens\": 12351, \"input_tokens\": 279, \"cost\": 0.06314999999999993}\n"
     ]
    }
   ],
   "source": [
    "# gpt4o mbti and api cost(per round)\n",
    "result_gpt4o = f.get_mbti(model='gpt-4o')\n",
    "print(json.dumps(result_gpt4o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_tem_gpt4o = f.get_mbti(\n",
    "    model='gpt-4o',\n",
    "    temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_tem_gpt4o = f.get_mbti(\n",
    "    model='gpt-4o',\n",
    "    temperature=1.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconditional_mbti_gpt4o = {}\n",
    "unconditional_mbti_gpt4o[\"0.5 temperature unconditional\"] = result_gpt4o\n",
    "unconditional_mbti_gpt4o[\"1 temperature unconditional\"] = middle_tem_gpt4o\n",
    "unconditional_mbti_gpt4o[\"1.7 temperature unconditional\"] = high_tem_gpt4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result of two models using a dict\n",
    "SAVE_PATH = 'mbti_results/llms_mbti93.json'\n",
    "\n",
    "llms_mbti = {}\n",
    "llms_mbti[\"gpt-3.5\"] = unconditional_mbti_gpt3\n",
    "llms_mbti[\"gpt-4o\"] = unconditional_mbti_gpt4o\n",
    "\n",
    "# Save the dictionary as a JSON object to the file\n",
    "with open(SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(llms_mbti, json_file, indent=4)  # indent=4 for pretty-printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional prompt (change LLMs' mbti via prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "# gpt 3.5\n",
    "personalities = json.load(\n",
    "    open('mbti_types/personality_traits.json', 'r', encoding='utf8')\n",
    ").keys()\n",
    "\n",
    "simple_35_condition_mbti = {}\n",
    "\n",
    "for p in personalities:\n",
    "\n",
    "    condi_prompt = (\n",
    "        'Your personality is'\n",
    "        + p\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-3.5-turbo', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    simple_35_condition_mbti[p] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "# gpt 3.5\n",
    "personality_traits = json.load(\n",
    "    open('mbti_types/personality_traits.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "complex_35_condition_mbti = {}\n",
    "\n",
    "for p in personality_traits.keys():\n",
    "\n",
    "    condi_prompt = (\n",
    "        f'You are a human with the following personality type:{p}.'\n",
    "        + f'Your traits are the following:{personality_traits[p][\"traits\"]}'\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-3.5-turbo', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    complex_35_condition_mbti[p] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "# gpt 4o\n",
    "personalities = json.load(\n",
    "    open('mbti_types/personality_traits.json', 'r', encoding='utf8')\n",
    ").keys()\n",
    "\n",
    "simple_4o_condition_mbti = {}\n",
    "\n",
    "for p in personalities:\n",
    "    \n",
    "    condi_prompt = (\n",
    "        'Your personality is'\n",
    "        + p\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-4o', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    simple_4o_condition_mbti[p] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "# gpt 4o\n",
    "personality_traits = json.load(\n",
    "    open('mbti_types/personality_traits.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "complex_4o_condition_mbti = {}\n",
    "\n",
    "for p in personality_traits.keys():\n",
    "\n",
    "    condi_prompt = (\n",
    "        f'You are a human with the following personality type:{p}.'\n",
    "        + f'Your traits are the following:{personality_traits[p][\"traits\"]}'\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-4o', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    complex_4o_condition_mbti[p] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "CONDI_SAVE_PATH = 'mbti_results/condition_mbti93.json'\n",
    "\n",
    "condition_mbti = {}\n",
    "condition_mbti['simple_35_condition'] = simple_35_condition_mbti\n",
    "condition_mbti['complex_35_condition'] = complex_35_condition_mbti\n",
    "condition_mbti['simple_4o_condition'] = simple_4o_condition_mbti\n",
    "condition_mbti['simple_4o_condition'] = complex_4o_condition_mbti\n",
    "\n",
    "with open(CONDI_SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(condition_mbti, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the accuracy\n",
    "condition_results = json.load(\n",
    "    open('mbti_results/condition_mbti93.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "accuracy_rate = {}\n",
    "\n",
    "for r in condition_results.keys(): # r: one of the four conditional mbti results\n",
    "    temp_acc_num = 0\n",
    "    temp_dim = [0, 0, 0, 0]\n",
    "    dim = ['I/E', 'N/S', 'F/T', 'P/J']\n",
    "    \n",
    "    for mbti_type in condition_results[r].keys(): # mbti_type: one of 16 MBTI personalities\n",
    "        res_mbti = condition_results[r][mbti_type]['res'] \n",
    "        \n",
    "        if mbti_type == res_mbti: # total accuracy\n",
    "            temp_acc_num += 1 \n",
    "        \n",
    "        for n in range(4):\n",
    "            if mbti_type[n] == res_mbti[n]: # accuracy of certain dimesion\n",
    "                temp_dim[n] += 1  \n",
    "\n",
    "    accuracy_rate[r] = {} # aggregate dict\n",
    "    accuracy_rate[r]['total'] = temp_acc_num / 16\n",
    "    \n",
    "    for d in range(4):\n",
    "        accuracy_rate[r][dim[d]] = temp_dim[d] / 16\n",
    "        \n",
    "    # print(r + ' done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simple_35_condition': {'total': 0.75,\n",
       "  'I/E': 1.0,\n",
       "  'N/S': 0.8125,\n",
       "  'F/T': 1.0,\n",
       "  'P/J': 0.9375},\n",
       " 'complex_35_condition': {'total': 0.875,\n",
       "  'I/E': 1.0,\n",
       "  'N/S': 0.9375,\n",
       "  'F/T': 1.0,\n",
       "  'P/J': 0.9375},\n",
       " 'simple_4o_condition': {'total': 0.9375,\n",
       "  'I/E': 1.0,\n",
       "  'N/S': 0.9375,\n",
       "  'F/T': 1.0,\n",
       "  'P/J': 1.0},\n",
       " 'complex_4o_condition': {'total': 0.9375,\n",
       "  'I/E': 1.0,\n",
       "  'N/S': 0.9375,\n",
       "  'F/T': 1.0,\n",
       "  'P/J': 1.0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
