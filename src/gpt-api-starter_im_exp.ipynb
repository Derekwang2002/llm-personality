{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one model, one question, certain temperature. Return an inclination on certain dimension of mbti.\n",
    "def get_model_answer(model, question, temperature=0.5, add_sys_prompt=''):\n",
    "    # You can force model to change mbti via 'add_sys_prompt', such as, \"Your personality is ????\"\"\n",
    "    system_prompt = 'You can only anwser one letter, A or B.' + add_sys_prompt \n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        response_format={ \"type\": \"text\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    cost_info['prompt_tokens'] += response.usage.prompt_tokens\n",
    "    cost_info['input_tokens'] += response.usage.completion_tokens\n",
    "    \n",
    "    if model == 'gpt-3.5-turbo':\n",
    "        cost_info['cost'] += response.usage.total_tokens * 0.5/1000000\n",
    "    elif model == 'gpt-4o':\n",
    "        cost_info['cost'] += response.usage.total_tokens * 5/1000000\n",
    "    \n",
    "    def extract_A_or_B(input_string):\n",
    "        # 使用正则表达式匹配大写字母A或B\n",
    "        match = re.search(r'[AB]', input_string)\n",
    "        if match:\n",
    "            return match.group()\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    choice = response.choices[0].message.content\n",
    "    choice = extract_A_or_B(choice)\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbti for one model\n",
    "def get_mbti(model, temperature=0.5, add_sys_prompt=''):\n",
    "    mbti_questions = json.load(\n",
    "        open('mbti_questions.json', 'r', encoding='utf8')\n",
    "    )\n",
    "\n",
    "    cur_model_score = {\n",
    "            'E': 0,\n",
    "            'I': 0,\n",
    "            'S': 0,\n",
    "            'N': 0,\n",
    "            'T': 0,\n",
    "            'F': 0,\n",
    "            'J': 0,\n",
    "            'P': 0\n",
    "        }\n",
    "\n",
    "    for i in range(3): \n",
    "        for q in mbti_questions.values():\n",
    "            question = q['question']\n",
    "            res = get_model_answer(\n",
    "                model=model, \n",
    "                temperature=temperature, \n",
    "                question=question,\n",
    "                add_sys_prompt=add_sys_prompt\n",
    "            )\n",
    "            # print(res)\n",
    "            mbti_choice = q[res]\n",
    "            cur_model_score[mbti_choice] += 1\n",
    "        \n",
    "    e_or_i = 'E' if cur_model_score['E'] > cur_model_score['I'] else 'I'\n",
    "    s_or_n = 'S' if cur_model_score['S'] > cur_model_score['N'] else 'N'\n",
    "    t_or_f = 'T' if cur_model_score['T'] > cur_model_score['F'] else 'F'\n",
    "    j_or_p = 'J' if cur_model_score['J'] > cur_model_score['P'] else 'P'\n",
    "\n",
    "    result = {\n",
    "        'model': model,\n",
    "        'details': cur_model_score,\n",
    "        'res': ''.join([e_or_i, s_or_n, t_or_f, j_or_p])\n",
    "    }\n",
    "    \n",
    "    return(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "\n",
    "# Change gpt3.5 and 4o LLMs' mbti via explicit prompt\n",
    "# ISFP__ENTJ 3.5\n",
    "# ESFP_INTJ  4.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ISFP_3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m personalities \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_explicit.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m cost_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m }\n\u001b[0;32m---> 11\u001b[0m exp_prompt_3 \u001b[38;5;241m=\u001b[39m \u001b[43mpersonalities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mISFP_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraits\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(exp_prompt_3)\n\u001b[1;32m     14\u001b[0m result3 \u001b[38;5;241m=\u001b[39m get_mbti(\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     16\u001b[0m     add_sys_prompt\u001b[38;5;241m=\u001b[39mexp_prompt_3\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ISFP_3'"
     ]
    }
   ],
   "source": [
    "# Simple Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "personalities = json.load(\n",
    "    open('prompt_explicit.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}\n",
    "exp_prompt_3 = personalities[\"ISFP_3\"].get('traits','')\n",
    "print(exp_prompt_3)\n",
    "\n",
    "result3 = get_mbti(\n",
    "    model='gpt-3.5-turbo', \n",
    "    add_sys_prompt=exp_prompt_3\n",
    ")\n",
    "result3 = result3 | cost_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_prompt_3_mbti = {}\n",
    "exp_prompt_3_mbti[\"imp_prompt_ISFP\"] = result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Exp_prompt_ISFP': {'model': 'gpt-3.5-turbo',\n",
       "  'details': {'E': 7,\n",
       "   'I': 56,\n",
       "   'S': 22,\n",
       "   'N': 59,\n",
       "   'T': 21,\n",
       "   'F': 48,\n",
       "   'J': 33,\n",
       "   'P': 33},\n",
       "  'res': 'INFP',\n",
       "  'prompt_tokens': 17979,\n",
       "  'input_tokens': 606,\n",
       "  'cost': 0.009292500000000002}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_prompt_3_mbti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have a personality type with the Extraverted, Observant, Feeling, and Prospecting traits.\n"
     ]
    }
   ],
   "source": [
    "personalities = json.load(\n",
    "    open('prompt_explicit.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "exp_prompt_4_mbti = {}\n",
    "\n",
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}\n",
    "exp_prompt = personalities[\"ESFP_4o\"].get('traits','')\n",
    "print(exp_prompt)\n",
    "\n",
    "result4 = get_mbti(\n",
    "    model='gpt-4o', \n",
    "    add_sys_prompt=exp_prompt\n",
    ")\n",
    "result4 = result4 | cost_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ISFP': {'traits': 'You have a personality type with the Introverted, Observant, Feeling, and Prospecting traits.'},\n",
       " 'ESFP': {'traits': 'You have a personality type with the Extraverted, Observant, Feeling, and Prospecting traits.'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ESFP': {'model': 'gpt-4o',\n",
       "  'details': {'E': 63,\n",
       "   'I': 0,\n",
       "   'S': 42,\n",
       "   'N': 36,\n",
       "   'T': 6,\n",
       "   'F': 66,\n",
       "   'J': 5,\n",
       "   'P': 61},\n",
       "  'res': 'ESFP',\n",
       "  'prompt_tokens': 18210,\n",
       "  'input_tokens': 279,\n",
       "  'cost': 0.0924450000000001}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_prompt_4_mbti={}\n",
    "exp_prompt_4_mbti[\"ESFP\"] = result4\n",
    "exp_prompt_4_mbti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "CONDI_SAVE_PATH = 'explicit_res.json'\n",
    "condition_mbti = {}\n",
    "condition_mbti['GPT-3.5'] = exp_prompt_3_mbti\n",
    "condition_mbti['GPT-4o'] = exp_prompt_4_mbti\n",
    "\n",
    "with open(CONDI_SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(condition_mbti, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Implicit prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you are going out for a whole day, you would:\\nA. Plan things to do and the time\\nB. Not make plans, just go with the flow\\nAnswer:B\\n\\nYou are usually:\\nA. A sociable person\\nB. A quiet person\\nAnswer:B\\n\\nYou would make friends with people who:\\nA. Often come up with new ideas\\nB. Are down-to-earth\\nAnswer:B\\n\\nYou often tend to:\\nA. Let your emotions control your reason\\nB. Let your reason control your emotions\\nAnswer:A\n"
     ]
    }
   ],
   "source": [
    "# 3.5\n",
    "# Simple Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "personalities = json.load(\n",
    "    open('prompt_implicit.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}\n",
    "imp_prompt_3 = personalities[\"ISFP_3\"].get('Q&A','')\n",
    "print(imp_prompt_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im_result3 = get_mbti(\n",
    "    model='gpt-3.5-turbo', \n",
    "    add_sys_prompt=imp_prompt_3\n",
    ")\n",
    "im_result3 = im_result3 | cost_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imp_prompt_ISFP': {'model': 'gpt-3.5-turbo',\n",
       "  'details': {'E': 43,\n",
       "   'I': 20,\n",
       "   'S': 35,\n",
       "   'N': 46,\n",
       "   'T': 14,\n",
       "   'F': 55,\n",
       "   'J': 39,\n",
       "   'P': 27},\n",
       "  'res': 'ENFJ',\n",
       "  'prompt_tokens': 77030,\n",
       "  'input_tokens': 491,\n",
       "  'cost': 0.03876050000000004}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "imp_prompt_3_mbti = {}\n",
    "imp_prompt_3_mbti[\"imp_prompt_ISFP\"] = im_result3\n",
    "imp_prompt_3_mbti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you are going out for a whole day, you would:\\nA. Plan things to do and the time\\nB. Not make plans, just go with the flow\\nAnswer:B\\n\\nYou are usually:\\nA. A sociable person\\nB. A quiet person\\nAnswer:A\\n\\nYou would make friends with people who:\\nA. Often come up with new ideas\\nB. Are down-to-earth\\nAnswer:B\\n\\nYou often tend to:\\nA. Let your emotions control your reason\\nB. Let your reason control your emotions\\nAnswer:A\n"
     ]
    }
   ],
   "source": [
    "# 4o\n",
    "personalities = json.load(\n",
    "    open('prompt_implicit.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "imp_prompt_4_mbti = {}\n",
    "\n",
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}\n",
    "imp_prompt = personalities[\"ESFP_4o\"].get('Q&A','')\n",
    "print(imp_prompt)\n",
    "\n",
    "im_result4 = get_mbti(\n",
    "    model='gpt-4o', \n",
    "    add_sys_prompt=imp_prompt\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ESFP': {'model': 'gpt-4o',\n",
       "  'details': {'E': 44,\n",
       "   'I': 19,\n",
       "   'S': 39,\n",
       "   'N': 42,\n",
       "   'T': 15,\n",
       "   'F': 54,\n",
       "   'J': 16,\n",
       "   'P': 50},\n",
       "  'res': 'ENFP',\n",
       "  'prompt_tokens': 44715,\n",
       "  'input_tokens': 279,\n",
       "  'cost': 0.2249700000000002}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_result4 = im_result4 | cost_info\n",
    "personalities\n",
    "imp_prompt_4_mbti={}\n",
    "imp_prompt_4_mbti[\"ESFP\"] = im_result4\n",
    "imp_prompt_4_mbti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# save to file\n",
    "CONDI_SAVE_PATH = 'implicit_res.json'\n",
    "condition_mbti = {}\n",
    "condition_mbti['GPT-3.5'] = imp_prompt_3_mbti\n",
    "condition_mbti['GPT-4o'] = imp_prompt_4_mbti\n",
    "\n",
    "with open(CONDI_SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(condition_mbti, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
